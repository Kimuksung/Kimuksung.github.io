---
layout: post
title:  "kubernetes Airflow 구성하기2 with. docker spark image "
author: Kimuksung
categories: [ K8S ]
tags: [ K8S, Airflow ]
# 댓글 기능
comments: False
image: assets/images/k8s.png
---

<br>
오늘은 Airflow에 원하는 Library를 Requirement로 Image화 시켜 적용 시키는 과정을 공유드리려고 합니다.
생각보다 구성하는데 오래 걸렸습니다. ㅠㅠ ( 야근과 에러의 연속으로 인하여 )

##### Requirements 구성
---
- Airflow Spark Library를 설치해보려고 합니다. 버전은 2.0.0
- 아래와 같이 구성하여 줍니다.

```bash
# requirements.txt
apache-airflow-providers-apache-spark==2.0.0
```

##### Docker Image 구성
---
- Docker Image file을 가지고 위 파일과 같은 경로에 생성하여 줍니다.
- 아래와 같이 이름과 Tag 작업을 잘 빌드되면 됩니다.

```bash
# Dockerfile
FROM apache/airflow:2.6.2
COPY requirements.txt .
RUN pip install -r requirements.txt
```

```bash
# build image
$ docker build -t airflow-custom:1.0.0 .
$ docker images
```

![](https://i.ibb.co/qjvtL65/2023-08-28-7-52-50.png)

##### Clustesr에 Image 반영하기
---
- 반영한 Docker Image 파일을 각 Cluster에 적용시켜주어야 합니다.
- 그러기 위해서는 values.yaml 파일을 변경해주어야 합니다.
- Docker Image로 만든 이름과 TAG는 기억해두어야 합니다.
- defaultAirflowRepository에는 Name을 / defaultAirflowTag에는 Tag 명을 넣어줍니다.

```bash
# Default airflow repository -- overridden by all the specific images below
defaultAirflowRepository: airflow-custom

# Default airflow tag to deploy
defaultAirflowTag: "1.0.0"
```

```bash
$ helm upgrade --install airflow apache-airflow/airflow -n airflow -f values.yaml --debug
$ kubectl get pod -n airflow

$ kubectl exec airflow-webserver-pod -n airflow -- airflow providers list
```

- 아래 결과와 같이 spark version이 이상 없이 깔린 것을 볼 수 있습니다.
- 추가적으로 필요한 라이브러리가 있다면 Image를 만들어 반영하면 됩니다.

![](https://i.ibb.co/qCh9xYz/Untitled-7.png)

![](https://i.ibb.co/k6JC5Gz/2023-08-28-5-09-32.png)
